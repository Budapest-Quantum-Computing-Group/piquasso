{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiating CVQNN layers with Piquasso and Tensorflow\n",
    "\n",
    "In Piquasso, one can easily create Continuous-Variable Quantum Neural Networks (CVQNN) circuits using the [Piquasso CVQNN](https://docs.piquasso.com/misc/cvqnn.html) module. In these circuits, the layers are constructed according to [Continuous-variable quantum neural networks](https://arxiv.org/abs/1806.06871)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import piquasso as pq\n",
    "\n",
    "d = 2  # Number of qumodes\n",
    "\n",
    "layer_count = 10  # Number of CVQNN layers\n",
    "\n",
    "# Generating random weights\n",
    "weights = pq.cvqnn.generate_random_cvqnn_weights(layer_count=layer_count, d=d)\n",
    "\n",
    "# Creating CVQNN layers as a Piquasso subprogram\n",
    "cvqnn_layers = pq.cvqnn.create_layers(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Piquasso automatically sets up a subprogram containing the instructions of the desired CVQNN layer. Now we can embed this subprogram in any Piquasso program. Let's choose the input state as a pure displaced state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The program definition\n",
    "with pq.Program() as program:\n",
    "    pq.Q() | pq.Vacuum()\n",
    "\n",
    "    for i in range(d):\n",
    "        pq.Q(i) | pq.Displacement(r=0.1)\n",
    "\n",
    "    pq.Q() | cvqnn_layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to choose the simulator which executes the instructions. Since a CVQNN layer includes non-linear terms, we definitely need to perform the simulation in Fock space. Since our initial state is pure, we can use [PureFockSimulator](https://docs.piquasso.com/simulators/fock.html#module-piquasso._backends.fock.pure.simulator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 5\n",
    "\n",
    "simulator = pq.PureFockSimulator(d, pq.Config(cutoff=cutoff))\n",
    "\n",
    "final_state = simulator.execute(program).state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After obtaining the state, we can calculate several things, e.g. the expectation value of the position operator on mode 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean position on mode 0:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13816424588589984"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mean position on mode 0:\")\n",
    "final_state.mean_position(mode=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to differentiate quantitities, we need to modify the simulation. In itself, `PureFockSimulator` is unable to perform automatic differentiation. In order to do that, we can use `TensorflowCalculator`, which replaces NumPy to TensorFlow under the hood. For a concrete example, let the loss function be\n",
    "$$\n",
    "J(w) = || \\ket{\\psi(w)} - \\ket{\\psi_*} ||_2,\n",
    "$$\n",
    "where $\\ket{\\psi(w)}$ is the final state of the circuit, and $\\ket{\\psi_*}$ is some random final state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import comb\n",
    "\n",
    "state_vector_size = comb(d + cutoff - 1, cutoff - 1, exact=True)\n",
    "\n",
    "psi_star = np.random.rand(state_vector_size) + 1j * np.random.rand(state_vector_size)\n",
    "\n",
    "psi_star /= np.sum(np.abs(psi_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, by using [tf.GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape), we can differentiate this loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.9143935803818333\n",
      "Loss gradient: [[ 2.74908233e-02  1.90579159e-02 -1.36359733e-01 -7.89900742e-01\n",
      "   6.31235971e-02  4.51359355e-02  1.37501359e-02 -1.49146064e-01\n",
      "   7.07124282e-01  6.13503400e-01 -1.86550761e-02 -3.30165378e-03\n",
      "  -1.93856132e-01 -8.64247494e-02]\n",
      " [-2.56806492e-02 -1.09311576e-02 -1.56869982e-01 -1.04084859e+00\n",
      "   2.62702500e-02 -2.82813720e-02 -2.47865528e-04 -1.62468196e-01\n",
      "   7.93002340e-01  6.26729485e-01  3.06385925e-03  6.08110349e-03\n",
      "  -1.93358322e-01 -1.24251943e-01]\n",
      " [-9.50446575e-04  1.33989483e-02 -1.72803285e-01 -9.41667791e-01\n",
      "   4.26243569e-02 -1.48916159e-02 -1.07390412e-02 -1.76735043e-01\n",
      "   7.95963200e-01  6.87943272e-01 -2.03485134e-02  3.07257792e-04\n",
      "  -2.62790306e-01 -1.16476344e-01]\n",
      " [-3.72450937e-02 -2.08769879e-02 -1.76206568e-01 -1.02481323e+00\n",
      "   1.31557643e-02  4.54583859e-02 -3.87547982e-02 -1.36321748e-01\n",
      "   5.59320908e-01  7.49140192e-01  2.20169407e-02  9.05257291e-03\n",
      "  -1.29899478e-01 -1.74896858e-01]\n",
      " [ 1.05019969e-04  2.96898690e-02 -1.43994676e-01 -7.54722108e-01\n",
      "  -6.24264950e-03 -3.57365737e-04 -1.28056035e-03 -1.28966791e-01\n",
      "   2.83644410e-01  7.50169670e-01 -2.86531840e-03 -2.94652118e-03\n",
      "  -1.46905726e-01 -2.08311633e-01]\n",
      " [ 2.21149686e-02  2.43015951e-02 -1.56133705e-01 -9.28436747e-01\n",
      "  -1.66746793e-03  7.14612146e-03  2.58489956e-02 -1.93186037e-01\n",
      "   5.31515688e-01  6.09055925e-01  1.52602761e-02  1.38614499e-03\n",
      "  -2.36260723e-01 -4.58445297e-02]\n",
      " [ 6.53309771e-02 -2.25248193e-02 -1.55400942e-01 -7.55704086e-01\n",
      "   2.63295104e-02  2.94559557e-02  3.50726893e-02 -1.89213123e-01\n",
      "   4.12407710e-01  5.50960699e-01 -1.54967513e-02  5.48993909e-03\n",
      "  -2.81435368e-01 -2.00105841e-02]\n",
      " [ 3.44274524e-02 -2.03190650e-02 -1.84390809e-01 -4.22513813e-01\n",
      "   1.58696071e-02  8.22945595e-02 -1.49543722e-02 -1.79400696e-01\n",
      "  -4.00456378e-02  5.45120187e-01  2.63574528e-02  1.10389349e-02\n",
      "  -1.95466824e-01 -4.08803929e-02]\n",
      " [ 9.02318953e-02 -4.12075524e-02 -1.11835691e-01 -1.67807471e-01\n",
      "   1.56246309e-01  1.48121746e-01  2.65225963e-02 -1.46001858e-01\n",
      "  -1.60486680e-02  6.14163284e-01  8.16482930e-03 -1.02582859e-02\n",
      "  -1.76109094e-01 -6.65508202e-02]\n",
      " [ 1.13505831e-01  9.22094689e-03 -1.47057976e-01  2.07171604e-01\n",
      "  -2.92567093e-02  1.28038370e-01 -3.22500557e-02 -1.16794425e-01\n",
      "  -4.06023308e-01  4.96784484e-01 -6.60607912e-04 -4.50802342e-03\n",
      "  -1.40750466e-01 -1.37714650e-01]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")  # Turns off complex->float casting warnings\n",
    "\n",
    "simulator = pq.PureFockSimulator(\n",
    "    d, pq.Config(cutoff=cutoff), calculator=pq.TensorflowCalculator()\n",
    ")\n",
    "\n",
    "w = tf.Variable(weights)\n",
    "psi_star = tf.Variable(psi_star)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    cvqnn_layers = pq.cvqnn.create_layers(w)\n",
    "\n",
    "    with pq.Program() as program:\n",
    "        pq.Q() | pq.Vacuum()\n",
    "\n",
    "        for i in range(d):\n",
    "            pq.Q(i) | pq.Displacement(r=0.1)\n",
    "\n",
    "        pq.Q() | cvqnn_layers\n",
    "\n",
    "    simulator.execute(program)\n",
    "\n",
    "    final_state = simulator.execute(program).state\n",
    "\n",
    "    psi = final_state.state_vector\n",
    "\n",
    "    loss = tf.math.reduce_sum(tf.math.abs(psi - psi_star))\n",
    "\n",
    "loss_grad = tape.gradient(loss, w)\n",
    "\n",
    "print(f\"Loss: {loss.numpy()}\")\n",
    "print(f\"Loss gradient: {loss_grad.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, Piquasso is written in a way that it supports `tf.function` (see [Better performance with tf.function](https://www.tensorflow.org/guide/function)) one can also use `tf.function` for this task. Refactoring everything into a function, we can use the `tf.function` decorator. Note, that we have to avoid side effects in any function decorated with `tf.function`, because side effects are only executed at the tracing step. Therefore, instantiation of `pq.Program` should happen by providing the instructions as constructor arguments, instead of using the `with` keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.894765747849647\n",
      "Loss gradient: [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -6.67345017e-01\n",
      "  -2.54874175e-02  3.58265820e-03  5.05677534e-04  1.94302250e-04\n",
      "  -3.64319186e-01 -3.45216700e-01 -1.69090137e-02 -3.40747922e-03\n",
      "  -1.60837509e-02 -1.98875566e-02]\n",
      " [-5.86457902e-03 -1.21035878e-03 -1.55043526e-02 -8.28271323e-01\n",
      "  -5.31066904e-02 -4.84554544e-03 -5.80812625e-05 -1.76544370e-02\n",
      "  -2.08216692e-01 -3.76865336e-01  3.10981158e-03  5.96160077e-03\n",
      "  -1.33899841e-02 -4.03384195e-02]\n",
      " [-1.13481850e-04  2.70243642e-03 -1.72470618e-02 -7.65970527e-01\n",
      "  -5.66513626e-02 -6.72089071e-03 -2.60329493e-03 -2.47237259e-02\n",
      "  -2.00357768e-01 -2.97848746e-01 -2.06781753e-02  3.50210960e-04\n",
      "  -5.56693537e-02 -3.67677830e-02]\n",
      " [-2.27468448e-02 -5.52633668e-03 -3.98755645e-02 -8.25417102e-01\n",
      "  -5.93043926e-02 -1.33327910e-03 -1.01042051e-02 -2.91571317e-02\n",
      "  -2.15611339e-01 -4.28961878e-01  2.08739184e-02  8.76651319e-03\n",
      "   1.37371206e-03 -3.89518705e-02]\n",
      " [-1.87892157e-03  5.37833154e-03 -1.36615448e-02 -6.60832069e-01\n",
      "  -7.50926043e-02  1.66176090e-03 -2.69420378e-04 -3.32022191e-03\n",
      "  -5.67039657e-01 -3.18571677e-01 -2.15852369e-03 -3.24521224e-03\n",
      "   5.43648096e-03 -8.73775296e-02]\n",
      " [ 5.83906099e-03  5.78558720e-03 -1.12643328e-02 -7.59793843e-01\n",
      "  -8.39855386e-02 -3.82600348e-03  5.24677735e-03 -2.42852382e-02\n",
      "  -5.37699722e-01 -2.89306496e-01  1.26668834e-02  1.58843215e-03\n",
      "  -1.64412272e-02  1.58689887e-03]\n",
      " [ 1.08151183e-02 -3.86266375e-03 -7.75569104e-03 -6.35436801e-01\n",
      "  -6.52459901e-02  4.55608881e-03  5.67185289e-03 -1.25209745e-02\n",
      "  -6.84289373e-01 -2.76063258e-01 -1.16825182e-02  6.52499073e-03\n",
      "  -3.72979633e-02  1.34568495e-02]\n",
      " [-4.64909781e-03 -2.41748233e-03 -2.17860103e-02 -3.72679393e-01\n",
      "  -9.42371925e-02 -2.09154875e-03 -2.31268274e-03 -2.69853795e-02\n",
      "  -8.49268956e-01 -4.65756010e-01  1.57119304e-02  9.46992785e-03\n",
      "  -1.06903690e-02  2.25057230e-02]\n",
      " [-7.53367015e-04 -3.61325745e-03 -7.66019162e-03 -2.33031317e-01\n",
      "   4.60533111e-02  3.46102688e-03  3.17252456e-03 -1.70539694e-02\n",
      "  -7.77413920e-01 -4.67818675e-01  5.11227161e-03 -9.04881094e-03\n",
      "  -1.14801215e-02  1.67166542e-02]\n",
      " [ 1.38092264e-02  8.79943126e-04 -1.28216409e-02  8.80894098e-02\n",
      "  -1.13189517e-01  1.94333555e-02 -4.34651204e-03 -1.00987109e-02\n",
      "  -8.91468707e-01 -6.32716995e-01 -3.00837745e-04 -3.35387969e-03\n",
      "  -4.99420175e-03 -1.61771839e-02]]\n"
     ]
    }
   ],
   "source": [
    "def calculate_loss(w, psi_star, cutoff):\n",
    "    d = pq.cvqnn.get_number_of_modes(w.shape[1])\n",
    "\n",
    "    simulator = pq.PureFockSimulator(\n",
    "        d,\n",
    "        pq.Config(cutoff=cutoff, normalize=False),\n",
    "        calculator=pq.TensorflowCalculator(decorate_with=tf.function),\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        cvqnn_layers = pq.cvqnn.create_layers(w)\n",
    "\n",
    "        preparation = [pq.Vacuum()]\n",
    "\n",
    "        program = pq.Program(instructions=preparation + cvqnn_layers.instructions)\n",
    "\n",
    "        simulator.execute(program)\n",
    "\n",
    "        final_state = simulator.execute(program).state\n",
    "\n",
    "        psi = final_state.state_vector\n",
    "\n",
    "        loss = tf.math.reduce_sum(tf.math.abs(psi - psi_star))\n",
    "\n",
    "    return loss, tape.gradient(loss, w)\n",
    "\n",
    "\n",
    "improved_calculate_loss = tf.function(calculate_loss)\n",
    "\n",
    "loss, loss_grad = improved_calculate_loss(w, psi_star, cutoff)\n",
    "\n",
    "print(f\"Loss: {loss.numpy()}\")\n",
    "print(f\"Loss gradient: {loss_grad.numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first run is called the tracing step, and it takes some time, because Tensorflow captures a [tf.Graph](https://www.tensorflow.org/api_docs/python/tf/Graph) here. The size of the graph can be decreased by passing the `decorate_with=tf.function` argument to `pq.TensorflowCalculator`, which also decreases the execution time of the tracing step. After the first run, a significant speedup is observed. We can also compare the runtimes of the compiled and non-compiled function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular: 3.4202134370803834 s (+/- 0.5104111165502103 s).\n",
      "Improved: 0.0135833740234375 s (+/- 0.0009120222624867234 s).\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "regular_runtimes = []\n",
    "improved_runtimes = []\n",
    "\n",
    "for i in range(10):\n",
    "    w = tf.Variable(pq.cvqnn.generate_random_cvqnn_weights(layer_count, d))\n",
    "\n",
    "    start_time = time.time()\n",
    "    calculate_loss(w, psi_star, cutoff)\n",
    "    end_time = time.time()\n",
    "\n",
    "    regular_runtimes.append(end_time - start_time)\n",
    "\n",
    "    start_time = time.time()\n",
    "    improved_calculate_loss(w, psi_star, cutoff)\n",
    "    end_time = time.time()\n",
    "\n",
    "    improved_runtimes.append(end_time - start_time)\n",
    "\n",
    "print(f\"Regular: {np.mean(regular_runtimes)} s (+/- {np.std(regular_runtimes)} s).\")\n",
    "print(f\"Improved: {np.mean(improved_runtimes)} s (+/- {np.std(improved_runtimes)} s).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that is not everything yet! One can also create a similar function with the `jit_compile=True` flag, since every operation in Piquasso can be JIT-compiled using XLA through `tf.function`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-26 11:31:14.942992: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 5m4.497154802s\n",
      "\n",
      "********************************\n",
      "[Compiling module a_inference_calculate_loss_3303349__XlaMustCompile_true_config_proto_3175580994766145631_executor_type_11160318154034397263_.80211] Very slow compile? If you want to file a bug, run with envvar XLA_FLAGS=--xla_dump_to=/tmp/foo and attach the results.\n",
      "********************************\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float64, numpy=1.861646546992796>,\n",
       " <tf.Tensor: shape=(10, 14), dtype=float64, numpy=\n",
       " array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         -3.79367684e-01,  6.09711604e-01,  2.45689046e-04,\n",
       "         -2.38614997e-04, -1.62932343e-03, -5.77995886e-01,\n",
       "         -6.19436366e-01,  6.32017395e-03,  7.60270405e-04,\n",
       "          3.31421985e-03, -7.19956868e-04],\n",
       "        [-2.92014789e-03,  1.86369322e-03,  2.82715730e-03,\n",
       "         -3.29063648e-01,  6.37470378e-01, -1.38643771e-02,\n",
       "         -1.89973120e-03,  1.88512334e-02, -7.47652945e-01,\n",
       "         -4.52539548e-01, -2.44055629e-03,  3.16780214e-03,\n",
       "          3.28290996e-02, -2.80871126e-03],\n",
       "        [-9.76887143e-03,  2.62403637e-04,  1.61482734e-02,\n",
       "         -2.14483059e-01,  6.41185058e-01, -2.89731669e-03,\n",
       "         -1.29745999e-03,  1.56235068e-02, -8.20582857e-01,\n",
       "         -4.15654874e-01,  3.22268644e-04, -1.91732936e-02,\n",
       "          3.20189738e-02, -4.42354155e-02],\n",
       "        [ 1.28716325e-02,  4.06007913e-04,  1.55397676e-02,\n",
       "          4.11261294e-02,  6.10106914e-01,  9.07518304e-03,\n",
       "         -1.21150827e-03,  1.90009717e-02, -8.14739074e-01,\n",
       "         -2.77730166e-01,  1.78727969e-03,  3.45976906e-03,\n",
       "          4.15668960e-02, -2.03687240e-02],\n",
       "        [-1.26988973e-03, -4.17862070e-04,  2.12061135e-02,\n",
       "          4.06394263e-01,  4.14232157e-01,  9.45389364e-03,\n",
       "          2.11026699e-05,  1.42733946e-02, -8.46327684e-01,\n",
       "         -1.76403685e-01,  3.68172368e-03, -1.24242209e-02,\n",
       "          3.28416487e-02, -5.14717100e-02],\n",
       "        [ 2.02656499e-02, -1.95302840e-03,  1.99081467e-02,\n",
       "          4.81531956e-01,  2.30246472e-01,  4.52977158e-02,\n",
       "          1.33648959e-03, -1.30772882e-04, -9.08557129e-01,\n",
       "          2.16266419e-01,  3.82935921e-03, -1.06070946e-02,\n",
       "          2.99240325e-03, -8.25587365e-02],\n",
       "        [ 5.55688296e-02,  5.28513075e-05,  3.64573502e-03,\n",
       "          7.14807022e-01,  1.45822657e-01,  4.23116988e-02,\n",
       "          1.12064685e-03, -5.55032249e-04, -7.26621657e-01,\n",
       "          4.28019700e-02, -7.02700782e-03,  6.25116707e-04,\n",
       "         -1.55855993e-02, -2.09381614e-02],\n",
       "        [ 4.42606168e-02,  2.71816049e-04, -7.85385611e-03,\n",
       "          5.95152481e-01,  1.88270190e-01,  4.02904177e-02,\n",
       "          7.07011116e-04,  1.46435606e-04, -8.89045973e-01,\n",
       "         -8.68789011e-03,  3.38416364e-03,  1.49964953e-02,\n",
       "          1.29799416e-02, -1.59133988e-02],\n",
       "        [ 2.24029959e-02,  1.80867340e-04,  3.34973190e-03,\n",
       "          6.43381767e-01,  1.46549082e-01,  2.37843920e-02,\n",
       "         -3.00810933e-04,  1.02192336e-02, -8.99427733e-01,\n",
       "         -1.45560828e-02, -4.08714785e-03, -1.21357794e-02,\n",
       "          1.95175238e-02, -5.40407124e-02],\n",
       "        [ 3.40289559e-02, -8.63541911e-04,  6.99562762e-03,\n",
       "          6.24502755e-01,  2.41611450e-01,  1.02870678e-02,\n",
       "          1.19936305e-06,  7.13137153e-03, -8.13072795e-01,\n",
       "          2.77288166e-02,  3.59519097e-03,  6.34609065e-03,\n",
       "          2.19822492e-02,  2.67473454e-02]])>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jit_compiled_calculate_loss = tf.function(jit_compile=True)(calculate_loss)\n",
    "\n",
    "jit_compiled_calculate_loss(w, psi_star, cutoff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the same function takes significantly more time, but the compilation step results in an extra order of magnitude runtime improvement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regular:\t3.4202134370803834 s (+/- 0.5104111165502103 s).\n",
      "Improved:\t0.0135833740234375 s (+/- 0.0009120222624867234 s).\n",
      "JIT compiled:\t0.0016646862030029296 s (+/- 0.0001866165683130647 s).\n"
     ]
    }
   ],
   "source": [
    "jit_compiled_runtimes = []\n",
    "\n",
    "for i in range(10):\n",
    "    w = tf.Variable(pq.cvqnn.generate_random_cvqnn_weights(layer_count, d))\n",
    "\n",
    "    start_time = time.time()\n",
    "    jit_compiled_calculate_loss(w, psi_star, cutoff)\n",
    "    end_time = time.time()\n",
    "\n",
    "    jit_compiled_runtimes.append(end_time - start_time)\n",
    "\n",
    "print(f\"Regular:\\t{np.mean(regular_runtimes)} s (+/- {np.std(regular_runtimes)} s).\")\n",
    "print(f\"Improved:\\t{np.mean(improved_runtimes)} s (+/- {np.std(improved_runtimes)} s).\")\n",
    "print(\n",
    "    f\"JIT compiled:\\t{np.mean(jit_compiled_runtimes)} s \"\n",
    "    f\"(+/- {np.std(jit_compiled_runtimes)} s).\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to use this function for. e.g., quantum state learning. Consider the state\n",
    "$$\n",
    "\\ket{\\psi_*} = \\frac{1}{\\sqrt{2}} \\left ( \\ket{03} + \\ket{30} \\right ),\n",
    "$$\n",
    "which is the so-called NOON state for $N=3$. We can produce this using Piquasso:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pq.Program() as target_state_preparation:\n",
    "    pq.Q(all) | pq.StateVector([0, 3]) / np.sqrt(2)\n",
    "    pq.Q(all) | pq.StateVector([3, 0]) / np.sqrt(2)\n",
    "\n",
    "\n",
    "target_state = simulator.execute(target_state_preparation).state\n",
    "\n",
    "target_state_vector = target_state.state_vector\n",
    "\n",
    "psi_star = tf.Variable(target_state_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can demonstrate the speed of the JIT-compiled calculation by creating a simple optimization algorithm as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500:\t\t tf.Tensor(0.8148386265792411, shape=(), dtype=float64)\n",
      "1000:\t\t tf.Tensor(0.7873113596246494, shape=(), dtype=float64)\n",
      "1500:\t\t tf.Tensor(0.760595638101206, shape=(), dtype=float64)\n",
      "2000:\t\t tf.Tensor(0.8061251242374848, shape=(), dtype=float64)\n",
      "2500:\t\t tf.Tensor(0.8089312093720207, shape=(), dtype=float64)\n",
      "3000:\t\t tf.Tensor(0.37133245801501613, shape=(), dtype=float64)\n",
      "3500:\t\t tf.Tensor(0.276721172472077, shape=(), dtype=float64)\n",
      "4000:\t\t tf.Tensor(0.27085156102162544, shape=(), dtype=float64)\n",
      "4500:\t\t tf.Tensor(0.25758575067817163, shape=(), dtype=float64)\n",
      "5000:\t\t tf.Tensor(0.2605988937298275, shape=(), dtype=float64)\n",
      "5500:\t\t tf.Tensor(0.23163654370722436, shape=(), dtype=float64)\n",
      "6000:\t\t tf.Tensor(0.22739231353193629, shape=(), dtype=float64)\n",
      "6500:\t\t tf.Tensor(0.2363594837005884, shape=(), dtype=float64)\n",
      "7000:\t\t tf.Tensor(0.22506580630254558, shape=(), dtype=float64)\n",
      "7500:\t\t tf.Tensor(0.22863825020126977, shape=(), dtype=float64)\n",
      "8000:\t\t tf.Tensor(0.228557172932431, shape=(), dtype=float64)\n",
      "8500:\t\t tf.Tensor(0.2285893278142817, shape=(), dtype=float64)\n",
      "9000:\t\t tf.Tensor(0.2106788273492956, shape=(), dtype=float64)\n",
      "9500:\t\t tf.Tensor(0.21973064520402505, shape=(), dtype=float64)\n",
      "10000:\t\t tf.Tensor(0.19817656176241594, shape=(), dtype=float64)\n",
      "Final loss:\t tf.Tensor(0.19817656176241594, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "iterations = 10000\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "w = tf.Variable(pq.cvqnn.generate_random_cvqnn_weights(layer_count, d))\n",
    "\n",
    "\n",
    "for i in range(iterations):\n",
    "    loss, loss_grad = jit_compiled_calculate_loss(w, psi_star, cutoff)\n",
    "\n",
    "    optimizer.apply_gradients(zip([loss_grad], [w]))\n",
    "\n",
    "    if (i + 1) % (iterations // 20) == 0:\n",
    "        print(f\"{i+1}:\\t\\t\", loss)\n",
    "\n",
    "print(\"Final loss:\\t\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the final weights to calculate the final state, and calculate its fidelity with the target state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final state fidelity:  0.9992644012667061\n"
     ]
    }
   ],
   "source": [
    "program = pq.cvqnn.create_program(w)\n",
    "\n",
    "final_state = simulator.execute(program).state\n",
    "\n",
    "print(\"Final state fidelity: \", final_state.fidelity(target_state))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
